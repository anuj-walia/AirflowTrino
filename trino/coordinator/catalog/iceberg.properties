# The name of the connector is 'iceberg'
connector.name=iceberg

# Specify that the Iceberg catalog metadata will be stored in a JDBC database
iceberg.catalog.type=jdbc

# --- JDBC Metastorex Configuration (Example using PostgreSQL) ---
# The Java class name for the PostgreSQL JDBC driver
iceberg.jdbc-catalog.driver-class=org.postgresql.Driver

# The JDBC connection URL for your metastore database
iceberg.jdbc-catalog.connection-url=jdbc:postgresql://postgres:5432/airflow

# Credentials for the JDBC database
iceberg.jdbc-catalog.connection-user=airflow
iceberg.jdbc-catalog.connection-password=airflow

# A unique name for this catalog, which is used as a key in the metastore tables
iceberg.jdbc-catalog.catalog-name=main

# The root path in your object store where tables for this catalog will be created
iceberg.jdbc-catalog.default-warehouse-dir=s3a://anuj-iceberg/warehouse/

# --- S3 / MinIO Configuration ---
# Enable the S3 file system implementation
# you would have to create these using mc admin
# login to your cdocker container for minio
# create an alias for your minio cluster
# mc admin accesskey create local/ --access-key myaccesskey --secret-key mysecretkey
# mc alias set local http://localhost:9000 minioadmin minioadmin
# mc admin accesskey list local/ --all
hive.s3.aws-access-key=myaccesskey
hive.s3.aws-secret-key=mysecretkey

# The endpoint URL for your MinIO server
hive.s3.endpoint=http://minio:9000

# REQUIRED for MinIO: Use path-style access instead of virtual-host-style
hive.s3.path-style-access=true

# Optional but recommended: Disable SSL verification if MinIO is not using HTTPS
hive.s3.ssl.enabled=false

# REQUIRED for MinIO: Force the S3 client to use the credentials provided here
# fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
hive.s3.region=us-east-1
